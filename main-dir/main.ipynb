{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ag2ft_IGLFh",
        "outputId": "2a16ac03-467d-493d-cfe3-d21eca775888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1\n",
            "1.24.2\n",
            "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]\n",
            "1.2.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import sklearn\n",
        "print(pd.__version__)\n",
        "print(np.__version__)\n",
        "print(sys.version)\n",
        "print(sklearn.__version__)\n",
        "\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, roc_curve, classification_report,auc)\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In dataset preprocessing we didn't make any changes. All preprocessing parts have been preserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions of the Training set: (125973, 42)\n",
            "Dimensions of the Test set: (22544, 42)\n"
          ]
        }
      ],
      "source": [
        "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
        "\n",
        "# KDDTrain+_2.csv & KDDTest+_2.csv are the datafiles without the last column about the difficulty score\n",
        "# these have already been removed.\n",
        "df = pd.read_csv(\"KDDTrain+_2.csv\", header=None, names = col_names)\n",
        "df_test = pd.read_csv(\"KDDTest+_2.csv\", header=None, names = col_names)\n",
        "\n",
        "print('Dimensions of the Training set:',df.shape)\n",
        "print('Dimensions of the Test set:',df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>...</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "      <td>491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>26</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>neptune</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>232</td>\n",
              "      <td>8153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>199</td>\n",
              "      <td>420</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   duration protocol_type   service flag  src_bytes  dst_bytes  land   \n",
              "0         0           tcp  ftp_data   SF        491          0     0  \\\n",
              "1         0           udp     other   SF        146          0     0   \n",
              "2         0           tcp   private   S0          0          0     0   \n",
              "3         0           tcp      http   SF        232       8153     0   \n",
              "4         0           tcp      http   SF        199        420     0   \n",
              "\n",
              "   wrong_fragment  urgent  hot  ...  dst_host_srv_count   \n",
              "0               0       0    0  ...                  25  \\\n",
              "1               0       0    0  ...                   1   \n",
              "2               0       0    0  ...                  26   \n",
              "3               0       0    0  ...                 255   \n",
              "4               0       0    0  ...                 255   \n",
              "\n",
              "   dst_host_same_srv_rate  dst_host_diff_srv_rate   \n",
              "0                    0.17                    0.03  \\\n",
              "1                    0.00                    0.60   \n",
              "2                    0.10                    0.05   \n",
              "3                    1.00                    0.00   \n",
              "4                    1.00                    0.00   \n",
              "\n",
              "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate   \n",
              "0                         0.17                         0.00  \\\n",
              "1                         0.88                         0.00   \n",
              "2                         0.00                         0.00   \n",
              "3                         0.03                         0.04   \n",
              "4                         0.00                         0.00   \n",
              "\n",
              "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate   \n",
              "0                  0.00                      0.00                  0.05  \\\n",
              "1                  0.00                      0.00                  0.00   \n",
              "2                  1.00                      1.00                  0.00   \n",
              "3                  0.03                      0.01                  0.00   \n",
              "4                  0.00                      0.00                  0.00   \n",
              "\n",
              "   dst_host_srv_rerror_rate    label  \n",
              "0                      0.00   normal  \n",
              "1                      0.00   normal  \n",
              "2                      0.00  neptune  \n",
              "3                      0.01   normal  \n",
              "4                      0.00   normal  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>...</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>125973.00000</td>\n",
              "      <td>1.259730e+05</td>\n",
              "      <td>1.259730e+05</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "      <td>125973.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>287.14465</td>\n",
              "      <td>4.556674e+04</td>\n",
              "      <td>1.977911e+04</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.022687</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.204409</td>\n",
              "      <td>0.001222</td>\n",
              "      <td>0.395736</td>\n",
              "      <td>0.279250</td>\n",
              "      <td>...</td>\n",
              "      <td>182.148945</td>\n",
              "      <td>115.653005</td>\n",
              "      <td>0.521242</td>\n",
              "      <td>0.082951</td>\n",
              "      <td>0.148379</td>\n",
              "      <td>0.032542</td>\n",
              "      <td>0.284452</td>\n",
              "      <td>0.278485</td>\n",
              "      <td>0.118832</td>\n",
              "      <td>0.120240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2604.51531</td>\n",
              "      <td>5.870331e+06</td>\n",
              "      <td>4.021269e+06</td>\n",
              "      <td>0.014086</td>\n",
              "      <td>0.253530</td>\n",
              "      <td>0.014366</td>\n",
              "      <td>2.149968</td>\n",
              "      <td>0.045239</td>\n",
              "      <td>0.489010</td>\n",
              "      <td>23.942042</td>\n",
              "      <td>...</td>\n",
              "      <td>99.206213</td>\n",
              "      <td>110.702741</td>\n",
              "      <td>0.448949</td>\n",
              "      <td>0.188922</td>\n",
              "      <td>0.308997</td>\n",
              "      <td>0.112564</td>\n",
              "      <td>0.444784</td>\n",
              "      <td>0.445669</td>\n",
              "      <td>0.306557</td>\n",
              "      <td>0.319459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>4.400000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.760000e+02</td>\n",
              "      <td>5.160000e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42908.00000</td>\n",
              "      <td>1.379964e+09</td>\n",
              "      <td>1.309937e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7479.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           duration     src_bytes     dst_bytes           land   \n",
              "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000  \\\n",
              "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
              "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
              "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
              "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
              "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
              "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
              "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
              "\n",
              "       wrong_fragment         urgent            hot  num_failed_logins   \n",
              "count   125973.000000  125973.000000  125973.000000      125973.000000  \\\n",
              "mean         0.022687       0.000111       0.204409           0.001222   \n",
              "std          0.253530       0.014366       2.149968           0.045239   \n",
              "min          0.000000       0.000000       0.000000           0.000000   \n",
              "25%          0.000000       0.000000       0.000000           0.000000   \n",
              "50%          0.000000       0.000000       0.000000           0.000000   \n",
              "75%          0.000000       0.000000       0.000000           0.000000   \n",
              "max          3.000000       3.000000      77.000000           5.000000   \n",
              "\n",
              "           logged_in  num_compromised  ...  dst_host_count   \n",
              "count  125973.000000    125973.000000  ...   125973.000000  \\\n",
              "mean        0.395736         0.279250  ...      182.148945   \n",
              "std         0.489010        23.942042  ...       99.206213   \n",
              "min         0.000000         0.000000  ...        0.000000   \n",
              "25%         0.000000         0.000000  ...       82.000000   \n",
              "50%         0.000000         0.000000  ...      255.000000   \n",
              "75%         1.000000         0.000000  ...      255.000000   \n",
              "max         1.000000      7479.000000  ...      255.000000   \n",
              "\n",
              "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate   \n",
              "count       125973.000000           125973.000000           125973.000000  \\\n",
              "mean           115.653005                0.521242                0.082951   \n",
              "std            110.702741                0.448949                0.188922   \n",
              "min              0.000000                0.000000                0.000000   \n",
              "25%             10.000000                0.050000                0.000000   \n",
              "50%             63.000000                0.510000                0.020000   \n",
              "75%            255.000000                1.000000                0.070000   \n",
              "max            255.000000                1.000000                1.000000   \n",
              "\n",
              "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate   \n",
              "count                125973.000000                125973.000000  \\\n",
              "mean                      0.148379                     0.032542   \n",
              "std                       0.308997                     0.112564   \n",
              "min                       0.000000                     0.000000   \n",
              "25%                       0.000000                     0.000000   \n",
              "50%                       0.000000                     0.000000   \n",
              "75%                       0.060000                     0.020000   \n",
              "max                       1.000000                     1.000000   \n",
              "\n",
              "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate   \n",
              "count         125973.000000             125973.000000         125973.000000  \\\n",
              "mean               0.284452                  0.278485              0.118832   \n",
              "std                0.444784                  0.445669              0.306557   \n",
              "min                0.000000                  0.000000              0.000000   \n",
              "25%                0.000000                  0.000000              0.000000   \n",
              "50%                0.000000                  0.000000              0.000000   \n",
              "75%                1.000000                  1.000000              0.000000   \n",
              "max                1.000000                  1.000000              1.000000   \n",
              "\n",
              "       dst_host_srv_rerror_rate  \n",
              "count             125973.000000  \n",
              "mean                   0.120240  \n",
              "std                    0.319459  \n",
              "min                    0.000000  \n",
              "25%                    0.000000  \n",
              "50%                    0.000000  \n",
              "75%                    0.000000  \n",
              "max                    1.000000  \n",
              "\n",
              "[8 rows x 38 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution Training set:\n",
            "label\n",
            "normal             67343\n",
            "neptune            41214\n",
            "satan               3633\n",
            "ipsweep             3599\n",
            "portsweep           2931\n",
            "smurf               2646\n",
            "nmap                1493\n",
            "back                 956\n",
            "teardrop             892\n",
            "warezclient          890\n",
            "pod                  201\n",
            "guess_passwd          53\n",
            "buffer_overflow       30\n",
            "warezmaster           20\n",
            "land                  18\n",
            "imap                  11\n",
            "rootkit               10\n",
            "loadmodule             9\n",
            "ftp_write              8\n",
            "multihop               7\n",
            "phf                    4\n",
            "perl                   3\n",
            "spy                    2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Label distribution Training set:')\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution Test set:\n",
            "label\n",
            "normal             9711\n",
            "neptune            4657\n",
            "guess_passwd       1231\n",
            "mscan               996\n",
            "warezmaster         944\n",
            "apache2             737\n",
            "satan               735\n",
            "processtable        685\n",
            "smurf               665\n",
            "back                359\n",
            "snmpguess           331\n",
            "saint               319\n",
            "mailbomb            293\n",
            "snmpgetattack       178\n",
            "portsweep           157\n",
            "ipsweep             141\n",
            "httptunnel          133\n",
            "nmap                 73\n",
            "pod                  41\n",
            "buffer_overflow      20\n",
            "multihop             18\n",
            "named                17\n",
            "ps                   15\n",
            "sendmail             14\n",
            "rootkit              13\n",
            "xterm                13\n",
            "teardrop             12\n",
            "xlock                 9\n",
            "land                  7\n",
            "xsnoop                4\n",
            "ftp_write             3\n",
            "worm                  2\n",
            "loadmodule            2\n",
            "perl                  2\n",
            "sqlattack             2\n",
            "udpstorm              2\n",
            "phf                   2\n",
            "imap                  1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Label distribution Test set:')\n",
        "print(df_test['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "Feature 'protocol_type' has 3 categories\n",
            "Feature 'service' has 70 categories\n",
            "Feature 'flag' has 11 categories\n",
            "Feature 'label' has 23 categories\n",
            "\n",
            "Distribution of categories in service:\n",
            "service\n",
            "http        40338\n",
            "private     21853\n",
            "domain_u     9043\n",
            "smtp         7313\n",
            "ftp_data     6860\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# colums that are categorical and not binary yet: protocol_type (column 2), service (column 3), flag (column 4).\n",
        "\n",
        "# explore categorical features\n",
        "print('Training set:')\n",
        "for col_name in df.columns:\n",
        "    if df[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
        "\n",
        "#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\n",
        "print()\n",
        "print('Distribution of categories in service:')\n",
        "print(df['service'].value_counts().sort_values(ascending=False).head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set:\n",
            "Feature 'protocol_type' has 3 categories\n",
            "Feature 'service' has 64 categories\n",
            "Feature 'flag' has 11 categories\n",
            "Feature 'label' has 38 categories\n"
          ]
        }
      ],
      "source": [
        "# Test set\n",
        "print('Test set:')\n",
        "for col_name in df_test.columns:\n",
        "    if df_test[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df_test[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
        "\n",
        "# Test dataset has 6 missing data in service feature\n",
        "# and 15 extra categories in label feature but the labels will be examined on their own. \n",
        "# so we just create dummies for the service feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  protocol_type   service flag\n",
              "0           tcp  ftp_data   SF\n",
              "1           udp     other   SF\n",
              "2           tcp   private   S0\n",
              "3           tcp      http   SF\n",
              "4           tcp      http   SF"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# insert code to get a list of categorical columns into a variable, categorical_columns\n",
        "categorical_columns=['protocol_type', 'service', 'flag']\n",
        " # Get the categorical values into a 2D numpy array\n",
        "df_categorical_values = df[categorical_columns]\n",
        "testdf_categorical_values = df_test[categorical_columns]\n",
        "df_categorical_values.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dummy column preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dummies in train datasets:\n",
            "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n",
            "\n",
            "Dummies count:  84\n"
          ]
        }
      ],
      "source": [
        "# for each categorical variables in train dataset, we create dummy varibles, i.e. we create a new column for each category in the categorical variable.\n",
        "\n",
        "# protocol type\n",
        "unique_protocol=sorted(df.protocol_type.unique())\n",
        "string1 = 'Protocol_type_'\n",
        "unique_protocol2=[string1 + x for x in unique_protocol]\n",
        "# service\n",
        "unique_service=sorted(df.service.unique())\n",
        "string2 = 'service_'\n",
        "unique_service2=[string2 + x for x in unique_service]\n",
        "# flag\n",
        "unique_flag=sorted(df.flag.unique())\n",
        "string3 = 'flag_'\n",
        "unique_flag2=[string3 + x for x in unique_flag]\n",
        "# put together\n",
        "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
        "\n",
        "print (\"Dummies in train datasets:\")\n",
        "print(dumcols)\n",
        "\n",
        "# do same for service feature of test set\n",
        "unique_service_test=sorted(df_test.service.unique())\n",
        "unique_service2_test=[string2 + x for x in unique_service_test]\n",
        "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n",
        "print()\n",
        "print(\"Dummies count: \", len(dumcols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ecoding of the categorical values, each categorical value will be replaced by a unique number\n",
        "\n",
        "# train set\n",
        "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "# test set\n",
        "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  protocol_type   service flag\n",
              "0           tcp  ftp_data   SF\n",
              "1           udp     other   SF\n",
              "2           tcp   private   S0\n",
              "3           tcp      http   SF\n",
              "4           tcp      http   SF"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_categorical_values.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   protocol_type  service  flag\n",
              "0              1       20     9\n",
              "1              2       44     9\n",
              "2              1       49     5\n",
              "3              1       24     9\n",
              "4              1       24     9"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_categorical_values_enc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Protocol_type_icmp</th>\n",
              "      <th>Protocol_type_tcp</th>\n",
              "      <th>Protocol_type_udp</th>\n",
              "      <th>service_IRC</th>\n",
              "      <th>service_X11</th>\n",
              "      <th>service_Z39_50</th>\n",
              "      <th>service_aol</th>\n",
              "      <th>service_auth</th>\n",
              "      <th>service_bgp</th>\n",
              "      <th>service_courier</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_REJ</th>\n",
              "      <th>flag_RSTO</th>\n",
              "      <th>flag_RSTOS0</th>\n",
              "      <th>flag_RSTR</th>\n",
              "      <th>flag_S0</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 84 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Protocol_type_icmp  Protocol_type_tcp  Protocol_type_udp  service_IRC   \n",
              "0                 0.0                1.0                0.0          0.0  \\\n",
              "1                 0.0                0.0                1.0          0.0   \n",
              "2                 0.0                1.0                0.0          0.0   \n",
              "3                 0.0                1.0                0.0          0.0   \n",
              "4                 0.0                1.0                0.0          0.0   \n",
              "\n",
              "   service_X11  service_Z39_50  service_aol  service_auth  service_bgp   \n",
              "0          0.0             0.0          0.0           0.0          0.0  \\\n",
              "1          0.0             0.0          0.0           0.0          0.0   \n",
              "2          0.0             0.0          0.0           0.0          0.0   \n",
              "3          0.0             0.0          0.0           0.0          0.0   \n",
              "4          0.0             0.0          0.0           0.0          0.0   \n",
              "\n",
              "   service_courier  ...  flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR  flag_S0   \n",
              "0              0.0  ...       0.0        0.0          0.0        0.0      0.0  \\\n",
              "1              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
              "2              0.0  ...       0.0        0.0          0.0        0.0      1.0   \n",
              "3              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
              "4              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
              "\n",
              "   flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  \n",
              "0      0.0      0.0      0.0      1.0      0.0  \n",
              "1      0.0      0.0      0.0      1.0      0.0  \n",
              "2      0.0      0.0      0.0      0.0      0.0  \n",
              "3      0.0      0.0      0.0      1.0      0.0  \n",
              "4      0.0      0.0      0.0      1.0      0.0  \n",
              "\n",
              "[5 rows x 84 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#In the dataset that has been label encoded, one-hot encoding is applied to create a new column for each category using predefined dummy column names. \n",
        "# The column values are filled in as binary (0s and 1s).\n",
        "\n",
        "# For example, if the protocol_type value in the 0th row is \"tcp,\" then only the Protocol_type_tcp column is assigned a value of 1, \n",
        "# while the other protocol type columns get a value of 0.\n",
        "\n",
        "# train set\n",
        "enc = OneHotEncoder()\n",
        "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
        "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
        "\n",
        "# test set\n",
        "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
        "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
        "\n",
        "df_cat_data.head()\n",
        "# 84 new dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['service_urh_i',\n",
              " 'service_aol',\n",
              " 'service_red_i',\n",
              " 'service_http_8001',\n",
              " 'service_harvest',\n",
              " 'service_http_2784']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# there was 6 missing data in the service feature of the test set, \n",
        "# so we need to add these columns to the test set and fill them with 0s\n",
        "\n",
        "trainservice=df['service'].tolist()\n",
        "testservice= df_test['service'].tolist()\n",
        "difference=list(set(trainservice) - set(testservice))\n",
        "string = 'service_'\n",
        "difference=[string + x for x in difference]\n",
        "difference # missing 6 service feature in test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22544, 84)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for col in difference:\n",
        "    testdf_cat_data[col] = 0\n",
        "\n",
        "testdf_cat_data.shape\n",
        "# now test set has 84 dummy columns as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(125973, 123)\n",
            "(22544, 123)\n"
          ]
        }
      ],
      "source": [
        "# merge the encoded dummy columns for the categorical data with the original dataset and drop the categorical columns\n",
        "\n",
        "# train set\n",
        "newdf=df.join(df_cat_data)\n",
        "newdf.drop('flag', axis=1, inplace=True)\n",
        "newdf.drop('protocol_type', axis=1, inplace=True)\n",
        "newdf.drop('service', axis=1, inplace=True)\n",
        "\n",
        "# test data\n",
        "newdf_test=df_test.join(testdf_cat_data)\n",
        "newdf_test.drop('flag', axis=1, inplace=True)\n",
        "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
        "newdf_test.drop('service', axis=1, inplace=True)\n",
        "\n",
        "print(newdf.shape)\n",
        "print(newdf_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splitting Dataset For Each Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    0\n",
            "4    0\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# take label column\n",
        "labeldf=newdf['label']\n",
        "labeldf_test=newdf_test['label']\n",
        "\n",
        "# change the label column\n",
        "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
        "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
        "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
        "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
        "\n",
        "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
        "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
        "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
        "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
        "\n",
        "# put the new label column back\n",
        "newdf['label'] = newlabeldf\n",
        "newdf_test['label'] = newlabeldf_test\n",
        "\n",
        "print(newdf['label'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "Dimensions of DoS: (113270, 123)\n",
            "Dimensions of Probe: (78999, 123)\n",
            "Dimensions of R2L: (68338, 123)\n",
            "Dimensions of U2R: (67395, 123)\n",
            "Test:\n",
            "Dimensions of DoS: (17171, 123)\n",
            "Dimensions of Probe: (12132, 123)\n",
            "Dimensions of R2L: (12596, 123)\n",
            "Dimensions of U2R: (9778, 123)\n"
          ]
        }
      ],
      "source": [
        "# prepare which values will be dropped from the each attack dataset\n",
        "to_drop_DoS = [2,3,4]\n",
        "to_drop_Probe = [1,3,4]\n",
        "to_drop_R2L = [1,2,4]\n",
        "to_drop_U2R = [1,2,3]\n",
        "\n",
        "# prepare the datasets for the attacks\n",
        "DoS_df=newdf[~newdf['label'].isin(to_drop_DoS)]\n",
        "Probe_df=newdf[~newdf['label'].isin(to_drop_Probe)]\n",
        "R2L_df=newdf[~newdf['label'].isin(to_drop_R2L)]\n",
        "U2R_df=newdf[~newdf['label'].isin(to_drop_U2R)]\n",
        "\n",
        "#test\n",
        "DoS_df_test=newdf_test[~newdf_test['label'].isin(to_drop_DoS)]\n",
        "Probe_df_test=newdf_test[~newdf_test['label'].isin(to_drop_Probe)]\n",
        "R2L_df_test=newdf_test[~newdf_test['label'].isin(to_drop_R2L)]\n",
        "U2R_df_test=newdf_test[~newdf_test['label'].isin(to_drop_U2R)]\n",
        "\n",
        "print('Train:')\n",
        "print('Dimensions of DoS:' ,DoS_df.shape)\n",
        "print('Dimensions of Probe:' ,Probe_df.shape)\n",
        "print('Dimensions of R2L:' ,R2L_df.shape)\n",
        "print('Dimensions of U2R:' ,U2R_df.shape)\n",
        "print('Test:')\n",
        "print('Dimensions of DoS:' ,DoS_df_test.shape)\n",
        "print('Dimensions of Probe:' ,Probe_df_test.shape)\n",
        "print('Dimensions of R2L:' ,R2L_df_test.shape)\n",
        "print('Dimensions of U2R:' ,U2R_df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dataframes into X & Y\n",
        "# assign X as a dataframe of feautures and Y as a series of outcome variables\n",
        "# X input, Y expected output\n",
        "\n",
        "X_DoS = DoS_df.drop('label',axis=1)\n",
        "Y_DoS = DoS_df.label\n",
        "X_Probe = Probe_df.drop('label',axis=1)\n",
        "Y_Probe = Probe_df.label\n",
        "X_R2L = R2L_df.drop('label',axis=1)\n",
        "Y_R2L = R2L_df.label\n",
        "X_U2R = U2R_df.drop('label',axis=1)\n",
        "Y_U2R = U2R_df.label\n",
        "\n",
        "# test set\n",
        "X_DoS_test = DoS_df_test.drop('label',axis=1)\n",
        "Y_DoS_test = DoS_df_test.label\n",
        "X_Probe_test = Probe_df_test.drop('label',axis=1)\n",
        "Y_Probe_test = Probe_df_test.label\n",
        "X_R2L_test = R2L_df_test.drop('label',axis=1)\n",
        "Y_R2L_test = R2L_df_test.label\n",
        "X_U2R_test = U2R_df_test.drop('label',axis=1)\n",
        "Y_U2R_test = U2R_df_test.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test X:\n",
            "(17171, 122)\n",
            "(12132, 122)\n",
            "(12596, 122)\n",
            "(9778, 122)\n",
            "\n",
            "test Y:\n",
            "(17171,)\n",
            "(12132,)\n",
            "(12596,)\n",
            "(9778,)\n"
          ]
        }
      ],
      "source": [
        "print(\"test X:\")\n",
        "print(X_DoS_test.shape)\n",
        "print(X_Probe_test.shape)\n",
        "print(X_R2L_test.shape)\n",
        "print(X_U2R_test.shape)\n",
        "print()\n",
        "print(\"test Y:\")\n",
        "print(Y_DoS_test.shape)\n",
        "print(Y_Probe_test.shape)\n",
        "print(Y_R2L_test.shape)\n",
        "print(Y_U2R_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "122\n",
            "['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n",
            "\n",
            "122\n",
            "['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_hostnames', 'service_http', 'service_http_443', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH', 'service_urh_i', 'service_aol', 'service_red_i', 'service_http_8001', 'service_harvest', 'service_http_2784']\n"
          ]
        }
      ],
      "source": [
        "colNames=list(X_DoS)\n",
        "colNames_test=list(X_DoS_test)\n",
        "\n",
        "print(len(colNames))\n",
        "print(colNames)\n",
        "print()\n",
        "print(len(colNames_test))\n",
        "print(colNames_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalizing the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train set\n",
        "scaler1 = preprocessing.StandardScaler().fit(X_DoS)\n",
        "X_DoS=scaler1.transform(X_DoS)\n",
        "scaler2 = preprocessing.StandardScaler().fit(X_Probe)\n",
        "X_Probe=scaler2.transform(X_Probe)\n",
        "scaler3 = preprocessing.StandardScaler().fit(X_R2L)\n",
        "X_R2L=scaler3.transform(X_R2L)\n",
        "scaler4 = preprocessing.StandardScaler().fit(X_U2R)\n",
        "X_U2R=scaler4.transform(X_U2R)\n",
        "\n",
        "# test data\n",
        "scaler5 = preprocessing.StandardScaler().fit(X_DoS_test)\n",
        "X_DoS_test=scaler5.transform(X_DoS_test)\n",
        "scaler6 = preprocessing.StandardScaler().fit(X_Probe_test)\n",
        "X_Probe_test=scaler6.transform(X_Probe_test)\n",
        "scaler7 = preprocessing.StandardScaler().fit(X_R2L_test)\n",
        "X_R2L_test=scaler7.transform(X_R2L_test)\n",
        "scaler8 = preprocessing.StandardScaler().fit(X_U2R_test)\n",
        "X_U2R_test=scaler8.transform(X_U2R_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1.]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 1.])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(X_DoS.std(axis=0))\n",
        "\n",
        "X_Probe.std(axis=0)\n",
        "X_R2L.std(axis=0)\n",
        "X_U2R.std(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ANNOVA F-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we use ANOVA F-test to perform feature selection for our classification task. The F-test helps us evaluate which features have the most significant relationship with the target variable. Specifically, we apply the test to select the top 10% of features from the original dataset for four categories: DoS, Probe, R2L, and U2R."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "\n",
        "# This function selects the top 10% of features based on the ANOVA F-test score (f_classif is the scoring function).\n",
        "selector=SelectPercentile(f_classif, percentile=10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(113270, 13)\n",
            "['logged_in', 'count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'service_http', 'flag_S0', 'flag_SF']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 16  44  63  66  68  86 114] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# Fits the selector on the DoS dataset (X_DoS and Y_DoS), keeping only the top 10% of features.\n",
        "X_newDoS = selector.fit_transform(X_DoS,Y_DoS)\n",
        "print(X_newDoS.shape)\n",
        "\n",
        "true_DoS=selector.get_support() # Returns a boolean mask indicating which features were selected.\n",
        "newcolindex_DoS=[i for i, x in enumerate(true_DoS) if x] # Extracts the indices of the selected features.\n",
        "newcolname_DoS=list( colNames[i] for i in newcolindex_DoS ) # Retrieves the names of the selected features using the colNames list.\n",
        "print(newcolname_DoS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(78999, 13)\n",
            "['logged_in', 'rerror_rate', 'srv_rerror_rate', 'dst_host_srv_count', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'Protocol_type_icmp', 'service_eco_i', 'service_private', 'flag_SF']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 4 16] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "X_newProbe = selector.fit_transform(X_Probe,Y_Probe)\n",
        "print(X_newProbe.shape)\n",
        "\n",
        "true_Probe=selector.get_support()\n",
        "newcolindex_Probe=[i for i, x in enumerate(true_Probe) if x]\n",
        "newcolname_Probe=list( colNames[i] for i in newcolindex_Probe )\n",
        "print(newcolname_Probe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(68338, 13)\n",
            "['src_bytes', 'dst_bytes', 'hot', 'num_failed_logins', 'is_guest_login', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp', 'service_ftp_data', 'service_http', 'service_imap4', 'flag_RSTO']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  4  16  43  44  46  47  48  49  50  51  54  57  58  62  63  64  66  67\n",
            "  68  70  71  72  73  74  76  77  78  79  80  81  82  83  86  87  89  92\n",
            "  93  96  98  99 100 107 108 109 110 114] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "X_newR2L = selector.fit_transform(X_R2L,Y_R2L)\n",
        "print(X_newR2L.shape)\n",
        "\n",
        "true_R2L=selector.get_support()\n",
        "newcolindex_R2L=[i for i, x in enumerate(true_R2L) if x]\n",
        "newcolname_R2L=list( colNames[i] for i in newcolindex_R2L)\n",
        "print(newcolname_R2L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(67395, 13)\n",
            "['urgent', 'hot', 'root_shell', 'num_file_creations', 'num_shells', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp_data', 'service_http', 'service_telnet']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  4  16  43  44  46  47  48  49  50  51  54  57  58  62  63  64  66  67\n",
            "  68  70  71  72  73  74  75  76  77  78  79  80  81  82  83  86  87  89\n",
            "  92  93  96  98  99 100 107 108 109 110 114] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "X_newU2R = selector.fit_transform(X_U2R,Y_U2R)\n",
        "print(X_newU2R.shape)\n",
        "\n",
        "true_U2R=selector.get_support()\n",
        "newcolindex_U2R=[i for i, x in enumerate(true_U2R) if x]\n",
        "newcolname_U2R=list( colNames[i] for i in newcolindex_U2R)\n",
        "print(newcolname_U2R)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features selected for DoS: ['logged_in', 'count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'service_http', 'flag_S0', 'flag_SF'] \n",
            "\n",
            "Features selected for Probe: ['logged_in', 'rerror_rate', 'srv_rerror_rate', 'dst_host_srv_count', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'Protocol_type_icmp', 'service_eco_i', 'service_private', 'flag_SF'] \n",
            "\n",
            "Features selected for R2L: ['src_bytes', 'dst_bytes', 'hot', 'num_failed_logins', 'is_guest_login', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp', 'service_ftp_data', 'service_http', 'service_imap4', 'flag_RSTO'] \n",
            "\n",
            "Features selected for U2R: ['urgent', 'hot', 'root_shell', 'num_file_creations', 'num_shells', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'service_ftp_data', 'service_http', 'service_telnet'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Features selected for DoS:',newcolname_DoS, \"\\n\")\n",
        "print('Features selected for Probe:',newcolname_Probe, \"\\n\")\n",
        "print('Features selected for R2L:',newcolname_R2L, \"\\n\")\n",
        "print('Features selected for U2R:',newcolname_U2R, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make best IDS model several machine classifier are selected:\n",
        "- Logistic Regression (LR): A linear model for classification.\n",
        "- Gaussian Naive Bayes (NB): A probabilistic classifier based on Bayes' theorem.\n",
        "- Decision Tree (DT): A tree-based model that splits data into classes.\n",
        "- AdaBoost (AB): An ensemble learning method using boosting.\n",
        "- Random Forest (RF): An ensemble of decision trees using bagging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the end we build a Voting Classifier using these machine learning models (Logistic Regression, Naive Bayes, Decision Tree, AdaBoost, and Random Forest). By combining these models, we aim to improve the predictive performance for detecting each attacks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DoS Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the Probe attack classification models, the labels were originally 0 and 2. Since the binary method could not be used in this case, the labels were initially updated to 0 and 1, and all models were run. \n",
        "\n",
        "Afterward, in the R2L classification the label distribution in the dataset was examined, and considering the imbalance, the average values were changed to **weighted**. It was observed that the models performed better under these conditions. \n",
        "\n",
        "To try again, the attack label values were left as 0 and 2 in the Probe attack classification section, and the model score average continued to use the weighted parameter. Here too, an increase in the scores was observed. Then, the weighted approach was tested for the DoS and U2R datasets as well, and again, an improvement in model performance was noted.\n",
        "\n",
        "**As a result because of the imbalanced of the datasets the average values were continued with the weighted**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    67343\n",
              "1    45927\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DoS_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(113270, 13)\n",
            "(17171, 13)\n",
            "\n",
            "(113270, 13)\n",
            "(113270,)\n",
            "(17171,)\n",
            "(17171, 13)\n"
          ]
        }
      ],
      "source": [
        "# DoS_df contains both normal data and data related to DoS attacks. \n",
        "# We select the features that best represent DoS attacks from this dataset to train models \n",
        "# that can accurately detect and classify DoS attacks.\n",
        "\n",
        "new_DoS_dataset_annova=DoS_df [newcolname_DoS] \n",
        "new_DoS_testdataset_annova=DoS_df_test [newcolname_DoS]\n",
        "\n",
        "X_DoS = new_DoS_dataset_annova.iloc[:,0:new_DoS_dataset_annova.shape[1]] # inputs\n",
        "Y_DoS = DoS_df['label'] # outputs\n",
        "C_DoS = DoS_df_test['label'] # outputs for testing\n",
        "T_DoS = new_DoS_testdataset_annova.iloc[:,0:new_DoS_dataset_annova.shape[1]] # inputs for testing\n",
        "\n",
        "\n",
        "scaler_DoS = Normalizer().fit(X_DoS)\n",
        "trainX_DoS = scaler_DoS.transform(X_DoS)\n",
        "\n",
        "scaler_DoS = Normalizer().fit(T_DoS)\n",
        "testT_DoS = scaler_DoS.transform(T_DoS)\n",
        "\n",
        "traindata_DoS = np.array(trainX_DoS)\n",
        "trainlabel_DoS = np.array(Y_DoS)\n",
        "\n",
        "testdata_DoS = np.array(testT_DoS)\n",
        "testlabel_DoS = np.array(C_DoS)\n",
        "\n",
        "print(traindata_DoS.shape)\n",
        "print(testdata_DoS.shape)\n",
        "print()\n",
        "print(X_DoS.shape)\n",
        "print(Y_DoS.shape)\n",
        "print(C_DoS.shape)\n",
        "print(T_DoS.shape)\n",
        "# 13 selected DoS's features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Logistic Regression--------------\n",
            "Accuracy:  0.816\n",
            "Precision:  0.824\n",
            "Recall:  0.816\n",
            "F1 score:  0.811\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Logistic Regression--------------\")\n",
        "\n",
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelLR.fit(traindata_DoS, trainlabel_DoS)\n",
        "\n",
        "expected = testlabel_DoS\n",
        "np.savetxt('classical/DoSexpected.txt', expected, fmt='%01d')\n",
        "predicted = modelLR.predict(testdata_DoS)\n",
        "proba = modelLR.predict_proba(testdata_DoS)\n",
        "\n",
        "np.savetxt('classical/DoSpredictedlabelLR.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/DoSpredictedprobaLR.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Gaussian Naive Bayes--------------\n",
            "Accuracy:  0.813\n",
            "Precision:  0.814\n",
            "Recall:  0.813\n",
            "F1 score:  0.811\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Gaussian Naive Bayes--------------\")\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(traindata_DoS, trainlabel_DoS)\n",
        "\n",
        "expected = testlabel_DoS\n",
        "predicted = model.predict(testdata_DoS)\n",
        "proba = model.predict_proba(testdata_DoS)\n",
        "\n",
        "np.savetxt('classical/DoSpredictedlabelNB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/DoSpredictedprobaNB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Decision Tree--------------\n",
            "Accuracy:  0.845\n",
            "Precision:  0.853\n",
            "Recall:  0.845\n",
            "F1 score:  0.841\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Decision Tree--------------\")\n",
        "\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelDT.fit(traindata_DoS, trainlabel_DoS)\n",
        "\n",
        "expected = testlabel_DoS\n",
        "predicted = modelDT.predict(testdata_DoS)\n",
        "proba = modelDT.predict_proba(testdata_DoS)\n",
        "\n",
        "np.savetxt('classical/DoSpredictedlabelDT.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/DoSpredictedprobaDT.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Adaboost--------------\n",
            "Accuracy:  0.836\n",
            "Precision:  0.847\n",
            "Recall:  0.836\n",
            "F1 score:  0.832\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Adaboost--------------\")\n",
        "\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelAB.fit(traindata_DoS, trainlabel_DoS)\n",
        "\n",
        "expected = testlabel_DoS\n",
        "predicted = modelAB.predict(testdata_DoS)\n",
        "proba = modelAB.predict_proba(testdata_DoS)\n",
        "\n",
        "np.savetxt('classical/DoSpredictedlabelAB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/DoSpredictedprobaAB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Random Forest--------------\n",
            "Accuracy:  0.829\n",
            "Precision:  0.841\n",
            "Recall:  0.829\n",
            "F1 score:  0.824\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Random Forest--------------\")\n",
        "\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "modelRF = modelRF.fit(traindata_DoS, trainlabel_DoS)\n",
        "\n",
        "expected = testlabel_DoS\n",
        "predicted = modelRF.predict(testdata_DoS)\n",
        "proba = modelRF.predict_proba(testdata_DoS)\n",
        "np.savetxt('classical/DoSpredictedlabelRF.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/DoSpredictedprobaRF.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The VotingClassifier combines all the above models.\n",
        "Soft voting is used, meaning the classifier predicts the class label based on the average predicted probabilities of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Performance of Voting Classifier with DoS Dataset\n",
            "Accuracy: 0.826\n",
            "Precision: 0.836\n",
            "Recall: 0.826\n",
            "F1 Score: 0.822\n"
          ]
        }
      ],
      "source": [
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelNB = GaussianNB()\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "voting_clf_DoS = VotingClassifier(estimators=[\n",
        "    ('LR', modelLR),\n",
        "    ('NB', modelNB),\n",
        "    ('DT', modelDT),\n",
        "    ('Adaboost', modelAB),\n",
        "    ('RF', modelRF)\n",
        "], voting='soft')  \n",
        "\n",
        "voting_clf_DoS.fit(traindata_DoS, trainlabel_DoS)\n",
        "\n",
        "predicted = voting_clf_DoS.predict(testdata_DoS)\n",
        "proba = voting_clf_DoS.predict_proba(testdata_DoS)\n",
        "\n",
        "np.savetxt('classical/predictedlabelVotingDoS.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/predictedprobaVotingDoS.txt', proba)\n",
        "\n",
        "expected = testlabel_DoS\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "print(\"Prediction Performance of Voting Classifier with DoS Dataset\")\n",
        "print(\"Accuracy:\", (\"%.3f\" %accuracy))\n",
        "print(\"Precision:\", (\"%.3f\" %precision))\n",
        "print(\"Recall:\", (\"%.3f\" %recall))\n",
        "print(\"F1 Score:\", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probe Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    67343\n",
              "2    11656\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Probe_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(78999, 13)\n",
            "(12132, 13)\n"
          ]
        }
      ],
      "source": [
        "# get the Probe feature from the train and test set\n",
        "new_Probe_dataset_annova=Probe_df [newcolname_Probe]\n",
        "new_Probe_testdataset_annova=Probe_df_test [newcolname_Probe]\n",
        "\n",
        "X_Probe = new_Probe_dataset_annova.iloc[:,0:new_Probe_dataset_annova.shape[1]] # inputs\n",
        "Y_Probe = Probe_df['label']# outputs\n",
        "C_Probe = Probe_df_test['label'] # outputs for testing\n",
        "T_Probe = new_Probe_testdataset_annova.iloc[:,0:new_Probe_dataset_annova.shape[1]] # inputs for testing\n",
        "\n",
        "scaler_Probe = Normalizer().fit(X_Probe)\n",
        "trainX_Probe = scaler_Probe.transform(X_Probe)\n",
        "\n",
        "scaler_Probe = Normalizer().fit(T_Probe)\n",
        "testT_Probe = scaler_Probe.transform(T_Probe)\n",
        "\n",
        "traindata_Probe = np.array(trainX_Probe)\n",
        "trainlabel_Probe = np.array(Y_Probe)\n",
        "\n",
        "testdata_Probe = np.array(testT_Probe)\n",
        "testlabel_Probe = np.array(C_Probe)\n",
        "\n",
        "print(traindata_Probe.shape) # (78999, 13)\n",
        "print(testdata_Probe.shape) # (12132, 13)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Logistic Regression--------------\n",
            "Accuracy:  0.880\n",
            "Precision:  0.876\n",
            "Recall:  0.880\n",
            "F1 score:  0.868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Logistic Regression--------------\")\n",
        "\n",
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelLR.fit(traindata_Probe, trainlabel_Probe)\n",
        "\n",
        "expected = testlabel_Probe\n",
        "np.savetxt('classical/Probeexpected.txt', expected, fmt='%01d')\n",
        "predicted = modelLR.predict(testdata_Probe)\n",
        "proba = modelLR.predict_proba(testdata_Probe)\n",
        "\n",
        "np.savetxt('classical/ProbepredictedlabelLR.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/ProbepredictedprobaLR.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Gaussian Naive Bayes--------------\n",
            "GaussianNB()\n",
            "Accuracy:  0.886\n",
            "Precision:  0.883\n",
            "Recall:  0.886\n",
            "F1 score:  0.875\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Gaussian Naive Bayes--------------\")\n",
        "\n",
        "modelNB = GaussianNB()\n",
        "modelNB.fit(traindata_Probe, trainlabel_Probe)\n",
        "print(modelNB)\n",
        "\n",
        "expected = testlabel_Probe\n",
        "predicted = modelNB.predict(testdata_Probe)\n",
        "proba = modelNB.predict_proba(testdata_Probe)\n",
        "\n",
        "np.savetxt('classical/ProbepredictedlabelNB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/ProbepredictedprobaNB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Decision Tree--------------\n",
            "DecisionTreeClassifier(class_weight='balanced')\n",
            "Accuracy:  0.884\n",
            "Precision:  0.881\n",
            "Recall:  0.884\n",
            "F1 score:  0.873\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Decision Tree--------------\")\n",
        "\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelDT.fit(traindata_Probe, trainlabel_Probe)\n",
        "print(modelDT)\n",
        "\n",
        "expected = testlabel_Probe\n",
        "predicted = modelDT.predict(testdata_Probe)\n",
        "proba = modelDT.predict_proba(testdata_Probe)\n",
        "\n",
        "np.savetxt('classical/ProbepredictedlabelDT.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/ProbepredictedprobaDT.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Adaboost--------------\n",
            "Accuracy:  0.892\n",
            "Precision:  0.889\n",
            "Recall:  0.892\n",
            "F1 score:  0.883\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Adaboost--------------\")\n",
        "\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelAB.fit(traindata_Probe, trainlabel_Probe)\n",
        "\n",
        "expected = testlabel_Probe\n",
        "predicted = modelAB.predict(testdata_Probe)\n",
        "proba = modelAB.predict_proba(testdata_Probe)\n",
        "\n",
        "np.savetxt('classical/ProbepredictedlabelAB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/ProbepredictedprobaAB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Random Forest--------------\n",
            "Accuracy:  0.888\n",
            "Precision:  0.885\n",
            "Recall:  0.888\n",
            "F1 score:  0.878\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Random Forest--------------\")\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "modelRF = modelRF.fit(traindata_Probe, trainlabel_Probe)\n",
        "\n",
        "expected = testlabel_Probe\n",
        "predicted = modelRF.predict(testdata_Probe)\n",
        "proba = modelRF.predict_proba(testdata_Probe)\n",
        "np.savetxt('classical/ProbepredictedlabelRF.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/ProbepredictedprobaRF.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Performance of Voting Classifier with Probe Dataset\n",
            "Accuracy: 0.889\n",
            "Precision: 0.885\n",
            "Recall: 0.889\n",
            "F1 Score: 0.879\n"
          ]
        }
      ],
      "source": [
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelNB = GaussianNB()\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "voting_clf_Probe = VotingClassifier(estimators=[\n",
        "    ('LR', modelLR),\n",
        "    ('NB', modelNB),\n",
        "    ('DT', modelDT),\n",
        "    ('Adaboost', modelAB),\n",
        "    ('RF', modelRF)\n",
        "], voting='soft')  \n",
        "\n",
        "voting_clf_Probe.fit(traindata_Probe, trainlabel_Probe)\n",
        "\n",
        "predicted = voting_clf_Probe.predict(testdata_Probe)\n",
        "proba = voting_clf_Probe.predict_proba(testdata_Probe)\n",
        "\n",
        "np.savetxt('classical/ProbepredictedlabelVotingProbe.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/ProbepredictedprobaVotingProbe.txt', proba)\n",
        "\n",
        "expected = testlabel_Probe\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Prediction Performance of Voting Classifier with Probe Dataset\")\n",
        "print(\"Accuracy:\", (\"%.3f\" %accuracy))\n",
        "print(\"Precision:\", (\"%.3f\" %precision))\n",
        "print(\"Recall:\", (\"%.3f\" %recall))\n",
        "print(\"F1 Score:\", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R2L Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    67343\n",
              "3      995\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "R2L_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(68338, 13)\n",
            "(12596, 13)\n"
          ]
        }
      ],
      "source": [
        "# get the R2L feature from the train and test set\n",
        "\n",
        "new_R2L_dataset_annova=R2L_df [newcolname_R2L]\n",
        "new_R2L_testdataset_annova=R2L_df_test [newcolname_R2L]\n",
        "\n",
        "X_R2L = new_R2L_dataset_annova.iloc[:,0:new_R2L_dataset_annova.shape[1]] # inputs\n",
        "Y_R2L = R2L_df['label'] # outputs\n",
        "C_R2L = R2L_df_test['label'] # outputs for testing\n",
        "T_R2L = new_R2L_testdataset_annova.iloc[:,0:new_R2L_dataset_annova.shape[1]] # inputs for testing\n",
        "\n",
        "scaler_R2L = Normalizer().fit(X_R2L)\n",
        "trainX_R2L = scaler_R2L.transform(X_R2L)\n",
        "\n",
        "scaler_R2L = Normalizer().fit(T_R2L)\n",
        "testT_R2L = scaler_R2L.transform(T_R2L)\n",
        "\n",
        "\n",
        "traindata_R2L = np.array(trainX_R2L)\n",
        "trainlabel_R2L = np.array(Y_R2L)\n",
        "\n",
        "testdata_R2L = np.array(testT_R2L)\n",
        "testlabel_R2L = np.array(C_R2L)\n",
        "\n",
        "print(traindata_R2L.shape)\n",
        "print(testdata_R2L.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Logistic Regression--------------\n",
            "Accuracy:  0.723\n",
            "Precision:  0.665\n",
            "Recall:  0.723\n",
            "F1 score:  0.685\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Logistic Regression--------------\")\n",
        "\n",
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelLR.fit(traindata_R2L, trainlabel_R2L)\n",
        "\n",
        "# make predictions\n",
        "expected = testlabel_R2L\n",
        "np.savetxt('classical/R2Lexpected.txt', expected, fmt='%01d')\n",
        "predicted = modelLR.predict(testdata_R2L)\n",
        "proba = modelLR.predict_proba(testdata_R2L)\n",
        "\n",
        "np.savetxt('classical/R2LpredictedlabelLR.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/R2LpredictedprobaLR.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Gaussian Naive Bayes-----------------\n",
            "GaussianNB()\n",
            "Accuracy:  0.850\n",
            "Precision:  0.851\n",
            "Recall:  0.850\n",
            "F1 score:  0.828\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------Gaussian Naive Bayes-----------------\")\n",
        "\n",
        "modelNB = GaussianNB()\n",
        "modelNB.fit(traindata_R2L, trainlabel_R2L)\n",
        "print(modelNB)\n",
        "# make predictions\n",
        "expected = testlabel_R2L\n",
        "predicted = modelNB.predict(testdata_R2L)\n",
        "proba = modelNB.predict_proba(testdata_R2L)\n",
        "\n",
        "np.savetxt('classical/R2LpredictedlabelNB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/R2LpredictedprobaNB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Decision Tree-----------------\n",
            "DecisionTreeClassifier(class_weight='balanced')\n",
            "Accuracy:  0.805\n",
            "Precision:  0.843\n",
            "Recall:  0.805\n",
            "F1 score:  0.743\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------Decision Tree-----------------\")\n",
        "\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelDT.fit(traindata_R2L, trainlabel_R2L)\n",
        "print(modelDT)\n",
        "\n",
        "expected = testlabel_R2L\n",
        "predicted = modelDT.predict(testdata_R2L)\n",
        "proba = modelDT.predict_proba(testdata_R2L)\n",
        "\n",
        "np.savetxt('classical/R2LpredictedlabelDT.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/R2LpredictedprobaDT.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Adaboost --------------\n",
            "Accuracy:  0.774\n",
            "Precision:  0.820\n",
            "Recall:  0.774\n",
            "F1 score:  0.679\n"
          ]
        }
      ],
      "source": [
        "print(\"------------ Adaboost --------------\")\n",
        "\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelAB.fit(traindata_R2L, trainlabel_R2L)\n",
        "\n",
        "expected = testlabel_R2L\n",
        "predicted = modelAB.predict(testdata_R2L)\n",
        "proba = modelAB.predict_proba(testdata_R2L)\n",
        "\n",
        "np.savetxt('classical/R2LpredictedlabelAB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/R2LpredictedprobaAB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Random Forest--------------\n",
            "Accuracy:  0.777\n",
            "Precision:  0.824\n",
            "Recall:  0.777\n",
            "F1 score:  0.686\n"
          ]
        }
      ],
      "source": [
        "print(\"------------Random Forest--------------\")\n",
        "\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "modelRF = modelRF.fit(traindata_R2L, trainlabel_R2L)\n",
        "\n",
        "expected = testlabel_R2L\n",
        "predicted = modelRF.predict(testdata_R2L)\n",
        "proba = modelRF.predict_proba(testdata_R2L)\n",
        "np.savetxt('classical/R2LpredictedlabelRF.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/R2LpredictedprobaRF.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Performance of Voting Classifier with R2L Dataset\n",
            "Accuracy: 0.808\n",
            "Precision: 0.839\n",
            "Recall: 0.808\n",
            "F1 Score: 0.750\n"
          ]
        }
      ],
      "source": [
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelNB = GaussianNB()\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "voting_clf_R2L = VotingClassifier(estimators=[\n",
        "    ('LR', modelLR),\n",
        "    ('NB', modelNB),\n",
        "    ('DT', modelDT),\n",
        "    ('Adaboost', modelAB),\n",
        "    ('RF', modelRF)\n",
        "], voting='soft')  \n",
        "\n",
        "voting_clf_R2L.fit(traindata_R2L, trainlabel_R2L)\n",
        "\n",
        "predicted = voting_clf_R2L.predict(testdata_R2L)\n",
        "proba = voting_clf_R2L.predict_proba(testdata_R2L)\n",
        "\n",
        "np.savetxt('classical/R2LpredictedlabelVoting.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/R2LpredictedprobaVoting.txt', proba)\n",
        "\n",
        "expected = testlabel_R2L\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\") \n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\") \n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\") \n",
        "\n",
        "\n",
        "print(\"Prediction Performance of Voting Classifier with R2L Dataset\")\n",
        "print(\"Accuracy:\", (\"%.3f\" %accuracy))\n",
        "print(\"Precision:\", (\"%.3f\" %precision))\n",
        "print(\"Recall:\", (\"%.3f\" %recall))\n",
        "print(\"F1 Score:\", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## U2R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    67343\n",
              "4       52\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "U2R_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(67395, 13)\n",
            "(9778, 13)\n"
          ]
        }
      ],
      "source": [
        "# get the U2R feature from the train and test set\n",
        "\n",
        "new_U2R_dataset_annova=U2R_df [newcolname_U2R]\n",
        "new_U2R_testdataset_annova=U2R_df_test [newcolname_U2R]\n",
        "\n",
        "X_U2R = new_U2R_dataset_annova.iloc[:,0:new_U2R_dataset_annova.shape[1]] # inputs\n",
        "Y_U2R = U2R_df['label']# outputs\n",
        "C_U2R = U2R_df_test['label'] # outputs for testing\n",
        "T_U2R = new_U2R_testdataset_annova.iloc[:,0:new_U2R_dataset_annova.shape[1]] # inputs for testing\n",
        "\n",
        "scaler_U2R = Normalizer().fit(X_U2R)\n",
        "trainX_U2R = scaler_U2R.transform(X_U2R)\n",
        "\n",
        "scaler_U2R = Normalizer().fit(T_U2R)\n",
        "testT_U2R = scaler_U2R.transform(T_U2R)\n",
        "\n",
        "\n",
        "traindata_U2R = np.array(trainX_U2R)\n",
        "trainlabel_U2R = np.array(Y_U2R)\n",
        "\n",
        "testdata_U2R = np.array(testT_U2R)\n",
        "testlabel_U2R = np.array(C_U2R)\n",
        "\n",
        "print(traindata_U2R.shape)\n",
        "print(testdata_U2R.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Logistic Regression-----------------\n",
            "Accuracy:  0.960\n",
            "Precision:  0.991\n",
            "Recall:  0.960\n",
            "F1 score:  0.974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------Logistic Regression-----------------\")\n",
        "\n",
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelLR.fit(traindata_U2R, trainlabel_U2R)\n",
        "\n",
        "expected = testlabel_U2R\n",
        "np.savetxt('classical/U2Rexpected.txt', expected, fmt='%01d')\n",
        "predicted = modelLR.predict(testdata_U2R)\n",
        "proba = modelLR.predict_proba(testdata_U2R)\n",
        "\n",
        "np.savetxt('classical/U2RpredictedlabelLR.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/U2RpredictedprobaLR.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Gaussian Naive Bayes-----------------\n",
            "GaussianNB()\n",
            "Accuracy:  0.992\n",
            "Precision:  0.992\n",
            "Recall:  0.992\n",
            "F1 score:  0.992\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------Gaussian Naive Bayes-----------------\")\n",
        "\n",
        "modelNB = GaussianNB()\n",
        "modelNB.fit(traindata_U2R, trainlabel_U2R)\n",
        "print(modelNB)\n",
        "\n",
        "expected = testlabel_U2R\n",
        "predicted = modelNB.predict(testdata_U2R)\n",
        "proba = modelNB.predict_proba(testdata_U2R)\n",
        "\n",
        "np.savetxt('classical/U2RpredictedlabelNB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/U2RpredictedprobaNB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Decision Tree-----------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(class_weight='balanced')\n",
            "Accuracy:  0.991\n",
            "Precision:  0.989\n",
            "Recall:  0.991\n",
            "F1 score:  0.990\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------Decision Tree-----------------\")\n",
        "\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelDT.fit(traindata_U2R, trainlabel_U2R)\n",
        "print(modelDT)\n",
        "\n",
        "expected = testlabel_U2R\n",
        "predicted = modelDT.predict(testdata_U2R)\n",
        "proba = modelDT.predict_proba(testdata_U2R)\n",
        "\n",
        "np.savetxt('classical/U2RpredictedlabelDT.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/U2RpredictedprobaDT.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Adaboost-----------------\n",
            "Accuracy:  0.994\n",
            "Precision:  0.994\n",
            "Recall:  0.994\n",
            "F1 score:  0.991\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------Adaboost-----------------\")\n",
        "\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelAB.fit(traindata_U2R, trainlabel_U2R)\n",
        "\n",
        "expected = testlabel_U2R\n",
        "predicted = modelAB.predict(testdata_U2R)\n",
        "proba = modelAB.predict_proba(testdata_U2R)\n",
        "\n",
        "np.savetxt('classical/U2RpredictedlabelAB.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/U2RpredictedprobaAB.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Random Forest-----------------\n",
            "Accuracy:  0.994\n",
            "Precision:  0.994\n",
            "Recall:  0.994\n",
            "F1 score:  0.991\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------Random Forest-----------------\")\n",
        "\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "modelRF = modelRF.fit(traindata_U2R, trainlabel_U2R)\n",
        "\n",
        "expected = testlabel_U2R\n",
        "predicted = modelRF.predict(testdata_U2R)\n",
        "proba = modelRF.predict_proba(testdata_U2R)\n",
        "np.savetxt('classical/U2RpredictedlabelRF.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/U2RpredictedprobaRF.txt', proba)\n",
        "\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy: \", (\"%.3f\" %accuracy))\n",
        "print(\"Precision: \", (\"%.3f\" %precision))\n",
        "print(\"Recall: \", (\"%.3f\" %recall))\n",
        "print(\"F1 score: \", (\"%.3f\" %f1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Performance of Voting Classifier with U2R Dataset\n",
            "Accuracy: 0.993\n",
            "Precision: 0.992\n",
            "Recall: 0.993\n",
            "F1 Score: 0.992\n"
          ]
        }
      ],
      "source": [
        "modelLR = LogisticRegression(class_weight=\"balanced\")\n",
        "modelNB = GaussianNB()\n",
        "modelDT = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "modelAB = AdaBoostClassifier(n_estimators=100)\n",
        "modelRF = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "voting_clf_U2R = VotingClassifier(estimators=[\n",
        "    ('LR', modelLR),\n",
        "    ('NB', modelNB),\n",
        "    ('DT', modelDT),\n",
        "    ('Adaboost', modelAB),\n",
        "    ('RF', modelRF)\n",
        "], voting='soft') \n",
        "\n",
        "voting_clf_U2R.fit(traindata_U2R, trainlabel_U2R)\n",
        "\n",
        "predicted = voting_clf_U2R.predict(testdata_U2R)\n",
        "proba = voting_clf_U2R.predict_proba(testdata_U2R)\n",
        "\n",
        "np.savetxt('classical/U2RpredictedlabelVotingU2R.txt', predicted, fmt='%01d')\n",
        "np.savetxt('classical/U2RpredictedprobaVotingU2R.txt', proba)\n",
        "\n",
        "expected = testlabel_U2R\n",
        "y_train1 = expected\n",
        "y_pred = predicted\n",
        "accuracy = accuracy_score(y_train1, y_pred)\n",
        "recall = recall_score(y_train1, y_pred , average=\"weighted\")\n",
        "precision = precision_score(y_train1, y_pred , average=\"weighted\")\n",
        "f1 = f1_score(y_train1, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Prediction Performance of Voting Classifier with U2R Dataset\")\n",
        "print(\"Accuracy:\", (\"%.3f\" %accuracy))\n",
        "print(\"Precision:\", (\"%.3f\" %precision))\n",
        "print(\"Recall:\", (\"%.3f\" %recall))\n",
        "print(\"F1 Score:\", (\"%.3f\" %f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment through the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def predictAttack(dataset, model_type):\n",
        "  if len(dataset) == 0:\n",
        "    return \"Dataset is empty!\"\n",
        "\n",
        "  row_num = dataset.shape[0]\n",
        "  random_row = random.randint(0, row_num - 1)\n",
        "  # selected_row = dataset[random_row].reshape(1, -1)\n",
        "  selected_row = dataset[random_row].reshape(1, -1)\n",
        "  predict = None\n",
        "  expected = None\n",
        "\n",
        "  if model_type == \"voting_clf_DoS\":\n",
        "    predict = voting_clf_DoS.predict(selected_row)\n",
        "    expected = testlabel_DoS[random_row]\n",
        "\n",
        "  elif model_type == \"voting_clf_Probe\":\n",
        "    predict = voting_clf_Probe.predict(selected_row)\n",
        "    expected = testlabel_Probe[random_row]\n",
        "\n",
        "  elif model_type == \"voting_clf_R2L\":\n",
        "    predict = voting_clf_R2L.predict(selected_row)\n",
        "    expected = testlabel_R2L[random_row]\n",
        "\n",
        "  elif model_type == \"voting_clf_U2R\":\n",
        "    predict = voting_clf_U2R.predict(selected_row)\n",
        "    expected = testlabel_U2R[random_row]\n",
        "  else:\n",
        "    return \"Unknown model type.\"\n",
        "\n",
        "  return f\"The result of the selected model for the {random_row}th row in the given data set is {predict}.\\n For this row expected label is {expected}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DoS\n",
            "The result of the selected model for the 13556th row in the given data set is [1].\n",
            " For this row expected label is 1\n",
            "\n",
            "Probe\n",
            "The result of the selected model for the 1918th row in the given data set is [2].\n",
            " For this row expected label is 0\n",
            "\n",
            "R2L\n",
            "The result of the selected model for the 11706th row in the given data set is [0].\n",
            " For this row expected label is 3\n",
            "\n",
            "U2R\n",
            "The result of the selected model for the 4753th row in the given data set is [0].\n",
            " For this row expected label is 0\n"
          ]
        }
      ],
      "source": [
        "# Datasets\n",
        "# testdata_DoS\n",
        "# testdata_Probe\n",
        "# testdata_R2L\n",
        "# testdata_U2R\n",
        "\n",
        "# Models\n",
        "# voting_clf_DoS\n",
        "# voting_clf_Probe\n",
        "# voting_clf_R2L\n",
        "# voting_clf_U2R\n",
        "\n",
        "print(\"DoS\")\n",
        "result = predictAttack(testdata_DoS, \"voting_clf_DoS\")\n",
        "print(result)\n",
        "print()\n",
        "print(\"Probe\")\n",
        "result = predictAttack(testdata_Probe, \"voting_clf_Probe\")\n",
        "print(result)\n",
        "print()\n",
        "print(\"R2L\")\n",
        "result = predictAttack(testdata_R2L, \"voting_clf_R2L\")\n",
        "print(result)\n",
        "print()\n",
        "print(\"U2R\")\n",
        "result = predictAttack(testdata_U2R, \"voting_clf_U2R\")\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colaboratory'ye Hoş Geldiniz",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
